# The falsifiability of the Bayesian brain hypothesis

One key challenge faced by the Bayesian brain hypothesis is its potential lack of falsifiability. Falsifiability, as defined by Popper (1959), pertains to a scientific theory's ability to be empirically tested and potentially refuted. The Bayesian brain hypothesis, however, is not easily testable or refutable, which raises concerns regarding its status as a scientific theory (Bowers & Davis, 2012, as cited in Griffiths et al., 2012). 
Firstly, the hypothesis is built upon probabilistic models and statistical inference, making it inherently complex and challenging to verify or test empirically (Friston, 2010; Wiese, 2014). Due to the probabilistic nature of Bayesian inference, it is difficult to derive clear-cut predictions to test experimentally. Even if a specific prediction is generated, an observed deviation from the prediction may not necessarily falsify the hypothesis, as it could be attributed to other factors or noise in the data (Bowers & Davis, 2012, cited in Griffiths et al., 2012).
Secondly, the hypothesis employs abstract concepts, such as priors and free energy (Friston, 2010; Friston et al., 2006), which are challenging to operationalize and measure rigorously.
Despite the wealth of research supporting the Bayesian brain hypothesis and its utility in understanding cognitive processes (Kersten et al., 2004), there is a need for more concrete evidence demonstrating that the brain employs Bayesian principles to process and integrate sensory information. Friston (2010) acknowledges this challenge and links the Bayesian brain hypothesis to the theory of natural selection, which, although not strictly falsifiable, has proven to be a powerful explanatory framework.
In subsequent sections, I will examine some aspects that are not directly connected to the Bayesian brain hypothesis. Nonetheless, these critical aspects influence the discussion and should be considered when applying Bayes' theorem to cognition.

##	Transparency of Bayesian approaches in mathematics and statistics vs. the Bayesian brain hypothesis
In the fields of mathematics and statistics, transparency is essential for understanding and evaluating the assumptions and logic behind models (Gelman et al., 2013). Bayesian methods in these disciplines allow researchers to pinpoint inaccurate priors or incorrect calculations at any stage. For instance, consider the calculations from Appendix B: if the posterior probability appears to be incorrect, both the practitioner and the observer(s) can identify the root of the problem (e.g., a poorly chosen prior) independently. This transparency is particularly beneficial when updating priors with new information, leading to more precise probability estimates (Gelman et al., 2013). 
However, the Bayesian brain hypothesis does not provide the same level of transparency. Despite advancements in neuroimaging techniques like functional magnetic resonance imaging (fMRI) and EEG, researchers can only examine the internal representation of a Bayesian mind, not the appropriateness of its application (Friston, 2010). This constraint makes it difficult to evaluate the model's reliability and validity and raises questions about the actual neural mechanisms underlying the Bayesian brain hypothesis (Friston, 2010). 

##	The limits of intuitive probability
In Appendix B, I calculated an 81.4% probability of rain on a given day. Gigerenzer et al. (2005) investigated people's understanding of such probabilities, asking participants from five major cities to rank three interpretations of a 30% chance of rain tomorrow. The correct interpretation (that it will rain on 30% of the days like tomorrow) was only the most popular interpretation in New York. In the European cities, the preferred interpretation was that it would rain 30% of the time or in 30% of the area. All European samples picked the correct interpretation as the least appropriate one. Even though one must consider moderating effects (i.e., different degrees of exposure to probabilistic forecasts) when interpreting the study, however, it does indicate the limits of intuitiveness in day-to-day probabilities (see also Murphy et al., 1980; Handmer & Proudley, 2007).
Based on their results, Gigerenzer and colleagues (2005) advise experts to specify the reference class or the class of events to which a single-event probability refers. Given that, one can conclude that probabilities must be specifically learned, and a certain degree of expertise is needed to handle probabilities appropriately, which is also highlighted in Erwig and Walkingshaw (2009). Therefore, one might assume that experts in this field (e.g., mathematicians and statisticians) are immune to the biases presented within this paper. However, in the following section, I discuss empirical data that suggests that even experts in their field of expertise struggle with probabilities and their interpretations.

##	Probability and the pitfalls of expertise {#sec:pitfalls_expertise}
As highlighted in previous sections, probabilistic reasoning can be challenging for individuals without a formal education in mathematics or statistics (Erwig & Walkingshaw, 2019). However, one can argue that even for experts in mathematics and statistics, probability interpretation can be a complex and daunting task. Studies by Gigerenzer (2004) and Hoekstra et al. (2014) demonstrated that both mathematicians and statistics professors made errors in interpreting p-values and confidence intervals. Given that, expertise alone does not guarantee immunity from the pitfalls associated with probabilistic reasoning. In combination with the lack of transparency in the Bayesian brain hypothesis (Chapter 4.1), the unintuitive nature of probabilities (Chapter 4.2), and the susceptibility of experts to errors, all contribute to the complexity of probability interpretation.
