---
editor_options: 
  markdown: 
    wrap: sentence
---

# The problems of probabilistic reasoning

Probabilistic reasoning refers to the act of making judgments about uncertain events or outcomes using probabilities.
Erwig and Walkingshaw (2009) emphasize that probabilistic reasoning can be difficult for individuals lacking formal education in mathematics or statistics.
They further argue that even basic questions concerning conditional probabilities can be perplexing for those without the appropriate background.
Subsequently, fallacies connected to this type of reasoning will be explained.

## Berkson's paradox

Berkson's paradox is a specific type of statistical bias that arises when conclusions about a population are drawn from a sample that does not accurately represent the entire population (Berkson, 1946).
To illustrate Berkson's paradox, let's consider a hypothetical example involving the correlation between two health-related factors, A and B, which are independent in the entire population.
Suppose that factor A is the presence of a specific gene, and factor B is a particular lifestyle habit.
In the general population, there is no correlation between possessing the gene and engaging in the lifestyle habit.
However, when examining a subset of the population that is affected by a specific health condition, one might find a negative correlation between the presence of the gene and the lifestyle habit, even though there is no correlation in the general population.
This occurs because the health condition acts as a confounding variable, and the examined sample is not representative of the whole population.
When applied to the Bayesian brain hypothesis, Berkson's paradox may manifest in situations where the brain relies on non-representative samples to make decisions or predictions, leading to biased inferences (Griffiths et al., 2008).
For instance, an individual may have observed a small sample of events or interactions that are not representative of the overall population, and based on this limited information, their brain forms a biased belief or expectation about future occurrences.
This can occur in various cognitive processes, such as social perception (Kahneman & Tversky, 1973), decision-making (Tversky & Kahneman, 1981), and learning (Gershman, 2015), where individuals are likely to encounter non-representative samples due to selective attention, memory biases, or limited exposure.
Empirical evidence supporting the occurrence of this fallacy in cognition includes studies demonstrating biased judgments in probability estimation tasks (Tversky & Kahneman, 1974) and suboptimal decision-making in various contexts (Daw et al., 2005).

## Inverse fallacy

The inverse fallacy involves erroneously believing that the reverse of a conditional probability is the same as the conditional probability of the inverse event (Dahlman et al., 2016).
As shown in Appendix B, this fallacy can cause someone to incorrectly assume that if $P(B|A)$ is 0.7 (the probability the forecast predicts rain given that it will rain), then $P(A|B)$ must be 1 - 0.7 = 0.3 (the probability that it will rain given the forecast predicts rain).
In reality, one must apply Bayes' theorem to determine the correct probability, which is approximately 81.4% for$P(A|B)$ , rather than the incorrect assumption of 30%.
An empirical study by Casscells et al. (1978) investigated the occurrence of the inverse fallacy in cognition.
They examined physicians' comprehension of conditional probabilities in medical diagnosis.
The results revealed that a mere 18% of physicians provided the correct answer, while the majority fell prey to the inverse fallacy.
This supports the notion that the inverse fallacy can hinder the accurate application of Bayesian reasoning principles, even among medical professionals.

## Prosecutor's fallacy

The prosecutor's fallacy is a type of error that occurs when one assumes that the presence of a piece of evidence increases the probability of a hypothesis being true without taking into account the prior probability of the hypothesis and the probability of observing the evidence given the truth of the hypothesis.
This fallacy is frequently encountered in legal situations, where the likelihood of a defendant's guilt may be overstated based on evidence, such as a DNA match, without considering the relevant probabilities (Thompson & Schumann, 1987).
Take, for example, a situation in which a fingerprint found at a crime scene matches that of a suspect.
If the likelihood of a random fingerprint matching the suspect is 1 in 10,000, it might be tempting to assume the suspect is guilty, with a probability of 99.99%.
However, this line of reasoning neglects the prior probability of the suspect's guilt and the likelihood of observing the fingerprint evidence, given the truth of the hypothesis.
The prosecutor's fallacy arises when these probabilities are not considered, leading to inflated estimations of a suspect's guilt based solely on the evidence.
Within the realm of cognition and the Bayesian brain, the prosecutor's fallacy may emerge when individuals overestimate the likelihood of a certain outcome or hypothesis based on a single piece of evidence, neglecting to consider the relevant probabilities (Leung, 2002).
This fallacy has the potential to introduce bias into judgments and decision-making across various cognitive processes, such as reasoning, learning, and perception.
A study conducted by Thompson and Schumann (1987) found that participants were more prone to the prosecutor's fallacy when presented with evidence framed in a way that emphasized its uniqueness without underscoring the importance of considering prior probabilities and the likelihood of the evidence given the truth of the hypothesis.

## Monty Hall problem

The Monty Hall problem is a probability puzzle that is based on the television game show "Let's Make a Deal" (Chen & Wang, 2020).
In the game show scenario, a contestant is presented with three doors, with one of them hiding a valuable prize (e.g., a car) and the other two concealing less valuable prizes (e.g., goats).
The contestant selects one door, and the host, Monty Hall, reveals one of the unchosen doors without the valuable prize.
At this point, the contestant has the option to either stick with their initial choice or switch to the other unopened door.
The question arises: does the contestant have better odds of winning the valuable prize by switching doors or by staying with their initial selection?
Many people initially believe that the contestant's chances are 50-50, regardless of whether they switch or stick with their original choice.
However, the correct answer is that the contestant has a higher chance of winning the prize (\frac{2}{3} or 66.7%) if they switch doors, compared to a \frac{1}{3} or 33.3% chance if they stick with their original choice.
The Monty Hall problem contributes to the Bayesian brain discussion by demonstrating the impact of information presentation on individuals' probability estimations.
It reveals that people frequently fail to consider broader information, focusing on specific details instead.
This indicates that the brain might not consistently process information following Bayesian principles, which in turn affects probability judgments.
In a study by Krauss and Wang (2003), participants faced the Monty Hall problem and demonstrated a persistent preference for non-optimal strategies, indicating cognitive biases at play.
This evidence supports the notion that the brain's ability to apply Bayesian reasoning might be limited, highlighting the importance of understanding such biases in the context of human cognition.

## Gambler's fallacy

The gambler's fallacy is a cognitive bias that occurs when people mistakenly believe that the probability of a random event is influenced by previous outcomes.
For example, imagine a person tossing a fair coin and getting five consecutive heads.
They might believe that the next toss is more likely to result in tails because 'it's due.' This belief is fallacious because the outcome of each coin toss is independent of previous outcomes.
In a fair coin toss, the probability of getting heads or tails is always 50%, regardless of the sequence of previous outcomes.
Empirical evidence supporting the occurrence of the gambler's fallacy in cognition includes studies by Croson and Sundali (2005), who investigated the fallacy in casino settings.
They found that players tended to bet more on the opposite color in roulette after observing a streak of the same color, demonstrating the gambler's fallacy in action.
Another study by Roney and Trick (2009) examined the gambler's fallacy in sports.
They found that basketball players and fans exhibited the fallacy when predicting the outcomes of free throws.
Participants believed that a player who had made several successful throws in a row was more likely to miss the next one, despite the fact that each throw is an independent event.
As this and the previous sections have illustrated, prediction is difficult when it is conflicted with fallacies (Neth & Gigerenzer, 2015).
With that being said, I will further evaluate the falsifiability of the Bayesian brain hypotheses and additionally include certain aspects (i.e., transparency, limits, and pitfalls) in the following chapter.
