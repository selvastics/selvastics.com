<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Theoretical background | Probabilistic fallacies in the Bayesian brain – A critique of the Bayesian approach to cognition</title>
  <meta name="description" content="Selvastics" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Theoretical background | Probabilistic fallacies in the Bayesian brain – A critique of the Bayesian approach to cognition" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Selvastics" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Theoretical background | Probabilistic fallacies in the Bayesian brain – A critique of the Bayesian approach to cognition" />
  
  <meta name="twitter:description" content="Selvastics" />
  

<meta name="author" content="Clievins Selva" />


<meta name="date" content="2023-10-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="the-problems-of-probabilistic-reasoning.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Probabilistic fallacies in the Bayesian brain – A critique of the Bayesian approach to cognition</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="theoretical-background.html"><a href="theoretical-background.html"><i class="fa fa-check"></i><b>2</b> Theoretical background</a>
<ul>
<li class="chapter" data-level="2.1" data-path="theoretical-background.html"><a href="theoretical-background.html#explaining-human-cognition-with-bayes-theorem-perception-and-decision-making"><i class="fa fa-check"></i><b>2.1</b> Explaining human cognition with Bayes’ theorem: perception and decision-making</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="theoretical-background.html"><a href="theoretical-background.html#the-role-of-neuronal-surprise-in-the-bayesian-brain"><i class="fa fa-check"></i><b>2.1.1</b> The role of neuronal surprise in the Bayesian brain</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="theoretical-background.html"><a href="theoretical-background.html#mathematical-and-statistical-aspects-of-bayes-theorem"><i class="fa fa-check"></i><b>2.2</b> Mathematical and statistical aspects of Bayes’ theorem</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="theoretical-background.html"><a href="theoretical-background.html#introduction-to-problems-with-the-bayesian-approach"><i class="fa fa-check"></i><b>2.2.1</b> Introduction to problems with the Bayesian approach</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-problems-of-probabilistic-reasoning.html"><a href="the-problems-of-probabilistic-reasoning.html"><i class="fa fa-check"></i><b>3</b> The problems of probabilistic reasoning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-problems-of-probabilistic-reasoning.html"><a href="the-problems-of-probabilistic-reasoning.html#berksons-paradox"><i class="fa fa-check"></i><b>3.1</b> Berkson’s paradox</a></li>
<li class="chapter" data-level="3.2" data-path="the-problems-of-probabilistic-reasoning.html"><a href="the-problems-of-probabilistic-reasoning.html#inverse-fallacy"><i class="fa fa-check"></i><b>3.2</b> Inverse fallacy</a></li>
<li class="chapter" data-level="3.3" data-path="the-problems-of-probabilistic-reasoning.html"><a href="the-problems-of-probabilistic-reasoning.html#prosecutors-fallacy"><i class="fa fa-check"></i><b>3.3</b> Prosecutor’s fallacy</a></li>
<li class="chapter" data-level="3.4" data-path="the-problems-of-probabilistic-reasoning.html"><a href="the-problems-of-probabilistic-reasoning.html#monty-hall-problem"><i class="fa fa-check"></i><b>3.4</b> Monty Hall problem</a></li>
<li class="chapter" data-level="3.5" data-path="the-problems-of-probabilistic-reasoning.html"><a href="the-problems-of-probabilistic-reasoning.html#gamblers-fallacy"><i class="fa fa-check"></i><b>3.5</b> Gambler’s fallacy</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="the-falsifiability-of-the-bayesian-brain-hypothesis.html"><a href="the-falsifiability-of-the-bayesian-brain-hypothesis.html"><i class="fa fa-check"></i><b>4</b> The falsifiability of the Bayesian brain hypothesis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="the-falsifiability-of-the-bayesian-brain-hypothesis.html"><a href="the-falsifiability-of-the-bayesian-brain-hypothesis.html#transparency-of-bayesian-approaches-in-mathematics-and-statistics-vs.-the-bayesian-brain-hypothesis"><i class="fa fa-check"></i><b>4.1</b> Transparency of Bayesian approaches in mathematics and statistics vs. the Bayesian brain hypothesis</a></li>
<li class="chapter" data-level="4.2" data-path="the-falsifiability-of-the-bayesian-brain-hypothesis.html"><a href="the-falsifiability-of-the-bayesian-brain-hypothesis.html#the-limits-of-intuitive-probability"><i class="fa fa-check"></i><b>4.2</b> The limits of intuitive probability</a></li>
<li class="chapter" data-level="4.3" data-path="the-falsifiability-of-the-bayesian-brain-hypothesis.html"><a href="the-falsifiability-of-the-bayesian-brain-hypothesis.html#sec:pitfalls_expertise"><i class="fa fa-check"></i><b>4.3</b> Probability and the pitfalls of expertise</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>5</b> Discussion</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discussion.html"><a href="discussion.html#interpretation-of-findings"><i class="fa fa-check"></i><b>5.1</b> Interpretation of findings</a></li>
<li class="chapter" data-level="5.2" data-path="discussion.html"><a href="discussion.html#limitations-and-future-directions-for-research"><i class="fa fa-check"></i><b>5.2</b> Limitations and future directions for research</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>6</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#applied-bayes-theorem"><i class="fa fa-check"></i>Applied Bayes theorem</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#applied-bayes-theorem-with-unknown-unconditional-probability"><i class="fa fa-check"></i>Applied Bayes theorem with unknown unconditional probability</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probabilistic fallacies in the Bayesian brain – A critique of the Bayesian approach to cognition</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="theoretical-background" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Theoretical background<a href="theoretical-background.html#theoretical-background" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter, I initially explore the Bayesian brain approach, providing insights into its essential concepts and principles. Following that, I delve into the mathematical and statistical foundations of Bayes’ theorem, which serves as the backbone of this perspective. Subsequently, I address the difficulties and issues arising from the application of the Bayesian approach to cognition and discuss the broader fallacies of probabilistic reasoning that influence this viewpoint.</p>
<div id="explaining-human-cognition-with-bayes-theorem-perception-and-decision-making" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Explaining human cognition with Bayes’ theorem: perception and decision-making<a href="theoretical-background.html#explaining-human-cognition-with-bayes-theorem-perception-and-decision-making" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The human brain features the ability to adapt and update its beliefs about the world based on new information (Bain, 2016). Bayes’ theorem offers a mathematical framework for understanding how this process might work by facilitating the calculation of the probability of different events occurring, founded on the combination of prior knowledge and new evidence.
This process of integrating new evidence with prior knowledge, known as Bayesian inference, is thought to play a pivotal role in numerous aspects of human cognition, including perception, decision-making, and learning (Rahnev, 2019). Research suggests that the brain employs Bayesian principles to process sensory information and formulate predictions about the environment (Lee &amp; Mumford, 2003; Hasson, 2017; Sedley et al., 2016). In particular, the prefrontal cortex and the posterior parietal cortex have been associated with the integration of prior knowledge and new evidence during Bayesian inference (Herd et al., 2021).
Lee and Mumford (2003) proposed a hierarchical Bayesian model to explain the brain’s processes in the visual cortex, highlighting how the brain integrates prior knowledge with sensory input to perceive the environment. Similarly, Hasson (2017) investigated the neurobiology of uncertainty and its implications for statistical learning, demonstrating that the brain employs Bayesian principles when dealing with ambiguous or uncertain information.
As research delves deeper into the role of Bayesian principles in human cognition, our understanding of the brain’s use of this theorem will continue to expand. With this foundation in place, I move forward to a specific aspect of the Bayesian brain: neuronal surprise.</p>
<div id="the-role-of-neuronal-surprise-in-the-bayesian-brain" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> The role of neuronal surprise in the Bayesian brain<a href="theoretical-background.html#the-role-of-neuronal-surprise-in-the-bayesian-brain" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In their study, Qiao and colleagues (2023) showed that Bayesian surprise modulates connections between stimulus processing brain regions and control regions/networks. This modulation drives cognitive flexibility through control engagement, ultimately allowing the brain to adapt to varying control demands. This research provides valuable insights into the mechanisms underlying cognitive flexibility and the source of switch costs in cognitive tasks (Qiao et al., 2023). Additionally, Gijsen et al. (2021) investigated the cortical dynamics of the somatosensory learning system and identified neural signatures of Bayesian surprise. The study found that secondary somatosensory cortices represent confidence-corrected surprise, while indications of Bayesian surprise encoding are present in the primary somatosensory cortex. This dissociation suggests that early surprise signals may control subsequent model update rates, supporting the hypothesis that early somatosensory processing reflects Bayesian perceptual learning (Gijsen et al., 2021). Furthermore, Visalli et al. (2021) examined electroencephalographic correlates of temporal Bayesian belief updating and surprise. The study demonstrated that late positive, centro-parietally distributed event-related potentials are associated with surprise and belief updating. This evidence suggests that temporal predictions are computed using Bayesian principles and are reflected in P3 modulations, similar to other cognitive domains (Visalli et al., 2021).
These findings highlight the significance of neuronal surprise in the Bayesian brain, showcasing its role in cognitive control, perceptual learning, and belief updating. In the next chapter, I will review the mathematical and statistical underpinnings of this perspective to provide a deeper understanding of its foundations.</p>
</div>
</div>
<div id="mathematical-and-statistical-aspects-of-bayes-theorem" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Mathematical and statistical aspects of Bayes’ theorem<a href="theoretical-background.html#mathematical-and-statistical-aspects-of-bayes-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Bayes’ theorem is a crucial mathematical concept that plays a vital role in various fields of statistics and mathematics. This theorem explains that the likelihood of an event A occurring, considering that event B has already happened, equals the probability of event B taking place, given that event A has happened, multiplied by the chance of event A happening, and then divided by the likelihood of event B happening (Bayes, 1763). Mathematically, this relationship can be demonstrated as follows:
Let A and B be two events in a probability space. Let <span class="math inline">\(P(A)\)</span> and <span class="math inline">\(P(B)\)</span> be the probabilities of events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, respectively, and let <span class="math inline">\(P(A|B)\)</span> be the conditional probability of event <span class="math inline">\(A\)</span>, given event <span class="math inline">\(B\)</span>. Then, according to Bayes’ theorem, the relationship between these probabilities is given by:</p>
<p><span class="math display" id="eq:bayestheorem">\[\begin{equation}
  P(A | B) = \frac{P(B | A) \times P(A)}{P(B)}.
  \tag{2.1}
\end{equation}\]</span></p>
<p>When the unconditional probability <span class="math inline">\(P(B)\)</span> is not known, one can use the principle of disjoint events to expand it as follows:</p>
<p><span class="math display" id="eq:totalprobability">\[\begin{equation}
  P(B) = P(B | A)P(A) + P(B | \lnot A)P(\lnot A),
  \tag{2.2}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\lnot A\)</span> denotes the complement of event <span class="math inline">\(A\)</span>, i.e., the event that <span class="math inline">\(A\)</span> does not occur. Substituting this expression for <span class="math inline">\(P(B)\)</span> into the above equation for <span class="math inline">\(P(A | B)\)</span> gives us the alternative formulation of Bayes’ theorem:</p>
<p><span class="math display">\[\begin{equation}
  P(A | B) = \frac{P(B | A)P(A)}{P(B | A)P(A) + P(B | \lnot A)P(\lnot A)}
  \label{eq:Alt_Bayes_Theorem}
\end{equation}\]</span></p>
<p>This alternative formulation is particularly useful when one does not have access to the unconditional probability <span class="math inline">\(P(B)\)</span> but does have information about the conditional probabilities <span class="math inline">\(P(B | A)\)</span> and <span class="math inline">\(P(B | \lnot A)\)</span> (Jaynes, 2003).</p>
<p>Bayes’ theorem has been employed to tackle a variety of problems across mathematics and statistics, spanning statistical inference, machine learning, and data analysis (MacKay, 2003; Nasrabadi, 2006). It is a useful tool for updating our beliefs about the likelihood of different events based on new evidence or information and has been particularly useful in situations where the data or information being analyzed is uncertain or incomplete.
When the prior probabilities and additional information used in the calculation are accurate, Bayes’ theorem can provide accurate probabilities for the event in question (see Appendix A and Appendix B). The subsequent chapter addresses problems associated with Bayes’ theorem when such conditions are not fulfilled.</p>
<div id="introduction-to-problems-with-the-bayesian-approach" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Introduction to problems with the Bayesian approach<a href="theoretical-background.html#introduction-to-problems-with-the-bayesian-approach" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As previously stated, the reliability of the resulting probabilities can be affected when certain assumptions are not met. One crucial assumption of Bayes’ theorem is that event A and event B probabilities are statistically independent (Tenenbaum et al., 2011). This means that the probability of event A happening is not impacted by the likelihood of event B happening, and vice versa. If this assumption doesn’t hold, the calculations might be inaccurate (Tenenbaum et al., 2011).
Additionally, the accuracy of Bayesian computations is dependent on the presence of suitable prior probabilities. These prior probabilities embody our understanding or beliefs about how likely an event is to occur before we take into account any new evidence. If the prior probabilities are not accurately determined or do not genuinely represent the real likelihood of an event occurring, the resulting probabilities may be less dependable (Jaynes, 2003). It is critical to ascertain that all conditions of Bayes’ theorem are met to achieve a reliable probability. If any of these conditions are unmet, the resulting probability may also be incorrect. While these are just a few of the challenges and limitations linked to the Bayesian approach, it is important to take them into consideration when applying this method to more complex situations (see, e.g., Perfors et al., 2011). Keeping these challenges in mind, upcoming chapters will delve into the wider context of probabilistic reasoning, which entails making judgments about uncertain events or outcomes based on probabilities.
It is important to note that, due to the scope of this paper, I will not delve deeper into the problems of Bayes’ theorem in mathematical and statistical contexts. See Pourret and colleagues (2018) for a more comprehensive analysis.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-problems-of-probabilistic-reasoning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/01-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
